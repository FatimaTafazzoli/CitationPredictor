{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature extraction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOe25/Xfv0WeBe7G7XNnWNs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IhWN3l_Gsqsr"},"source":["import pandas as pd\r\n","import ast\r\n","import numpy as np\r\n","from statistics import mean\r\n","\r\n","data_papers = pd.read_csv('papers.csv')\r\n","data_authors = pd.read_csv('authors.csv')\r\n","data_orgs = pd.read_csv('orgs.csv')\r\n","\r\n","# \r\n","data_papers['self_cite_percent'] = \"\"\r\n","data_papers['journal_percent'] = \"\"\r\n","data_papers['conference_percent'] = \"\"\r\n","data_papers['patent_percent'] = \"\"\r\n","data_papers['book_percent'] = \"\"\r\n","data_papers['other_percent'] = \"\"\r\n","data_papers['productivity'] = \"\"\r\n","data_papers['title_length'] = \"\"\r\n","data_papers['H_index'] = \"\"\r\n","data_papers['max_H_index'] = \"\"\r\n","data_papers['references_ave_age'] = \"\"\r\n","\r\n","# \r\n","data_papers['journal_publications'] = \"\"\r\n","data_papers['organization_num'] = \"\" \r\n","data_papers['prev_citation_sum'] = \"\"\r\n","data_papers['faculty_impact'] = \"\" \r\n","\r\n","# \r\n","data_papers['paper_len'] = \"\"\r\n","data_papers['n_authors'] =  \"\" \r\n","data_papers['avg_cite'] = \"\"\r\n","data_papers['n_papers'] = \"\"\r\n","data_papers['n_references'] = \"\"\r\n","\r\n","\r\n","\r\n","for i in range(len(data_papers)):\r\n","    \r\n","    # \r\n","    percentages = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\r\n","    \r\n","    if str(data_papers['references'][i]) != 'nan':\r\n","        references_paper = ast.literal_eval(data_papers['references'][i])\r\n","        \r\n","        for j in references_paper:\r\n","            type_doc = data_papers.loc[data_papers['id'] == np.int64(j)]['doc_type'].tolist()\r\n","            if 'Journal' in type_doc:\r\n","                percentages[1] += 1\r\n","            elif 'Conference' in type_doc:\r\n","                percentages[2] += 1\r\n","            elif 'Patent' in type_doc:\r\n","                percentages[3] += 1\r\n","            elif 'Book' in type_doc:\r\n","                percentages[4] += 1\r\n","            elif len(type_doc) != 0:\r\n","                if str(type_doc[0]) != 'nan':\r\n","                    print(type_doc)\r\n","                    percentages[5] += 1\r\n","            \r\n","            publish_doc = data_papers.loc[data_papers['id'] == np.int64(j)]['publisher'].tolist()\r\n","            if data_papers['publisher'][i] in publish_doc:\r\n","                percentages[0] += 1\r\n","        \r\n","        if len(references_paper) != 0:  \r\n","            percentages = [x * 1.0 / len(references_paper) for x in percentages]\r\n","       \r\n","        data_papers['self_cite_percent'][i] = percentages[0]\r\n","        data_papers['journal_percent'][i] = percentages[1]\r\n","        data_papers['conference_percent'][i] = percentages[2]\r\n","        data_papers['patent_percent'][i] = percentages[3]\r\n","        data_papers['book_percent'][i] = percentages[4]\r\n","        data_papers['other_percent'][i] = percentages[5]\r\n","    \r\n","    # \r\n","    # journal_publications = the average number of papers published by an orgaization in one year\r\n","    authorsOrg = data_authors.loc[data_authors['id'] == data_papers['first_author'][i]]['org'].tolist()\r\n","    if str(authorsOrg[0]) != 'nan':\r\n","        data_papers['journal_publications'][i] = data_orgs.loc[data_orgs['name'] == authorsOrg[0]]['journal_publications'].tolist()[0]\r\n","    \r\n","    # organization_num = len(set(author.org))\r\n","    authors_ids = ast.literal_eval(data_papers['authors'][i])\r\n","    authors = []\r\n","    for ids in authors_ids:\r\n","        selected_author_org = data_authors.loc[data_authors['id'] == np.int64(ids), 'org'].tolist() \r\n","        if (str(selected_author_org[0]) !=  'nan'):\r\n","            authors.extend(selected_author_org)\r\n","            authors = list(set(authors))\r\n","    data_papers['organization_num'][i] = len(authors)\r\n","    \r\n","    # prev_citation_sum = Previous citations\r\n","    author = ast.literal_eval(data_papers['authors'][i])\r\n","    papers = ast.literal_eval(data_authors.loc[data_authors['id'] == np.int64(author[0])]['papers'].tolist()[0])\r\n","    sum_cite = 0\r\n","    for x in papers:\r\n","        # print(str(x))\r\n","        paper = data_papers.loc[data_papers['id'] == np.int64(x)]\r\n","        print(paper)\r\n","        n_citations = paper.loc[paper['year'] <= np.int64(data_papers['year'][i])]['n_citation'].tolist()\r\n","        print(\"n_citations\\t\\t\", n_citations)\r\n","        print(\"this\\t\", paper.loc[paper['year'] <= np.int64(data_papers['year'][i])])\r\n","        print(\"ttt\\t\", np.int64(data_papers['year'][i]))\r\n","        print(len(paper))\r\n","        if len(paper) != 0:\r\n","            if len(paper) != 1:\r\n","                print(\"\\t\", paper['year'][0])\r\n","                print(\"\\t\", type(paper['year'][0]))\r\n","            else:\r\n","                print(\"\\t\", paper['year'])\r\n","                print(\"\\t\", type(paper['year']))\r\n","        if len(n_citations) != 0:\r\n","            sum_cite += sum(n_citations)\r\n","    \r\n","    # faculty_impact = The average h-index among the authors affiliated with the institution of the first author\r\n","    author = ast.literal_eval(data_papers['authors'][i])\r\n","    org = data_authors.loc[data_authors['id'] == np.int64(author[0])]['org'].tolist()[0]\r\n","    if(str(org) != 'nan'):\r\n","        data_papers['faculty_impact'][i] = (data_orgs.loc[data_orgs['name'] == org]['ave_H_index'].tolist())[0]\r\n","\r\n","    #\r\n","    authorsPapers = (data_authors.loc[data_authors['id'] == data_papers['first_author'][i]]['papers'].tolist())[0]\r\n","    data_papers['productivity'][i] = len(ast.literal_eval(authorsPapers)) \r\n","    \r\n","    data_papers['title_length'][i] = len(data_papers['title'][i].split())\r\n","    \r\n","    data_papers['H_index'][i] = (data_authors.loc[data_authors['id'] == data_papers['first_author'][i]]['H_index'].tolist())[0]\r\n","    \r\n","    author = ast.literal_eval(data_papers['authors'][i])\r\n","    org = data_authors.loc[data_authors['id'] == np.int64(author[0])]['org'].tolist()[0]\r\n","    if(str(org) != 'nan'):\r\n","        data_papers['max_H_index'][i] = (data_orgs.loc[data_orgs['name'] == org]['max_H_index'].tolist())[0]\r\n","    \r\n","    if str(data_papers['references'][i]) != 'nan':\r\n","        sumYears = 0.0\r\n","        numYears = 0.0\r\n","        for ref in ast.literal_eval(data_papers['references'][i]):\r\n","            year = data_papers.loc[data_papers['id'] == np.int64(ref)]['year'].tolist()\r\n","            if len(year) != 0:\r\n","                sumYears += int(year[0])\r\n","                numYears += 1.0\r\n","        if numYears != 0:\r\n","            data_papers['references_ave_age'][i] = 2020 - sumYears/numYears\r\n","    \r\n","    \r\n","    # \r\n","    # Length of Paper - Casting as int() results in an error\r\n","    if str(data_papers['page_end'][i]) != 'nan' and str(data_papers['page_start'][i]) != 'nan':\r\n","        data_papers['paper_len'][i] = (np.float64(str(data_papers['page_end'][i]).replace('-', '')) - np.float64(str(data_papers['page_start'][i]).replace('-', ''))+1)\r\n","    \r\n","    # Number of Authors \r\n","    data_papers['n_authors'][i] = len(ast.literal_eval(data_papers['authors'][i]))\r\n","    \r\n","    # # Previous Citations per Article\r\n","    if data_papers['productivity'][i] != 0 and data_papers['productivity'][i] != \"\" and data_papers['prev_citation_sum'][i] != \"\":   \r\n","        data_papers['avg_cite'][i] = data_papers['prev_citation_sum'][i] / data_papers['productivity'][i]  \r\n","\r\n","    # Total Number of Papers Produced in the Institute \r\n","    author = ast.literal_eval(data_papers['authors'][i])\r\n","    org = data_authors.loc[data_authors['id'] == np.int64(author[0])]['org'].tolist()[0]\r\n","    if str(org) != 'nan':\r\n","        data_papers['n_papers'][i] = (data_orgs.loc[data_orgs['name'] == org]['num_of_papers'].tolist())[0]\r\n","\r\n","    # Number of References\r\n","    if str(data_papers['references'][i]) != 'nan':  \r\n","        data_papers['n_references'][i] = len(ast.literal_eval(data_papers['references'][i]))\r\n","\r\n","fileName = 'features.csv'\r\n","data_papers[['id', 'doc_type', 'journal_publications', 'organization_num', 'prev_citation_sum', 'faculty_impact', 'productivity', 'title_length', 'H_index', 'max_H_index', 'references_ave_age', 'self_cite_percent', 'journal_percent', 'conference_percent', 'patent_percent', 'book_percent', 'paper_len', 'avg_cite', 'n_papers', 'n_references', 'n_authors', 'n_citation']].to_csv(fileName, encoding='utf-8')"],"execution_count":null,"outputs":[]}]}